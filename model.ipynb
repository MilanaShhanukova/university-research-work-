{"cells":[{"metadata":{"id":"jrib7NWJrGTh","trusted":true,"outputId":"2cf01e76-4890-4cfd-c080-0bfbdedc08ec"},"cell_type":"code","source":"try:\n  from torchcrf import CRF\nexcept:\n  !pip install pytorch-crf\n  from torchcrf import CRF\ntry: \n  import pytorch_lightning.metrics as metrics\nexcept:\n  !pip install pytorch_lightning \n  import pytorch_lightning.metrics as metrics","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pytorch-crf\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nInstalling collected packages: pytorch-crf\nSuccessfully installed pytorch-crf-0.7.2\n","name":"stdout"}]},{"metadata":{"id":"Q2AIX2qFplxZ","trusted":true,"outputId":"6b0b2768-3c93-490a-b1de-80acab55c3ed"},"cell_type":"code","source":"import torch\nimport torch.autograd as autograd\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport time\nimport plotly as plt\nimport os\n\nimport numpy as np\nimport collections \ntorch.manual_seed(1)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<torch._C.Generator at 0x7f4944251810>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Here starts logic for working with data.\nSome points to notice:\n- we use preprocessed files \n- we use DataManager as the main instrument to preprocess everything\n- add your dir for func get_sentences"},{"metadata":{"id":"bTTjSWv9JJbs","trusted":true},"cell_type":"code","source":"def get_sentences(file_paths: list):\n      \"\"\"\n      :param file_paths: paths of file in the dir\n      :return: list of sentences parts\n      \"\"\"\n      sentences = []\n      for file_name in file_paths:\n          with open(file_name) as f:\n              sentence = []\n              for line in f:\n                  line_parts = line.strip().split(\"   \")\n                  if len(line_parts) != 1:\n                      sentence.append(line_parts)\n                  elif len(line_parts) == 1:\n                      sentences.append(sentence)\n                      sentence = []\n      return [sent for sent in sentences if len(sent) > 0]\n\nmy_dir_path = \"../input/data-mistakes\"\nfiles = [f for f in os.listdir(my_dir_path) if f.endswith(\".txt\")]","execution_count":4,"outputs":[]},{"metadata":{"id":"Rk5BrYTraHme","trusted":true,"outputId":"f1200059-17f1-48ba-ec71-32ee8313347f"},"cell_type":"code","source":"os.chdir(\"../input/data-mistakes\")\ndata = get_sentences(files)\n\nprint(f\"now we will train on {len(data)} sentences\")","execution_count":5,"outputs":[{"output_type":"stream","text":"now we will train on 484297 sentences\n","name":"stdout"}]},{"metadata":{"id":"3dnPgh7JI66I","trusted":true},"cell_type":"code","source":"#customized data manager\nclass DataManager:\n  def __init__(self):\n    self.PAD = \"<pad>\"\n\n\n    self.word_to_id = dict()\n    self.mistakes_to_id = dict()\n    self.speech_to_id = dict()\n    self.tree_to_id = dict()\n\n    self.singletons = []\n\n    self.train = []\n    self.val = []\n    self.test = []\n    \n    self.lengths = []\n\n  def build_vocabs(self, data_train: list, embedding_path=None):\n    \"\"\"\n    creates dicts for words, mistakes and part_speech tokens to use it then for decoding\n    :param data_train: data organised in conll format\n    :param embedding_path: path to embeddings, isn't used for 07/01/20\n    \"\"\"\n\n    data = data_train\n\n    word_counter = collections.Counter()\n    mistakes_counter = collections.Counter()\n    parts_speech_counter = collections.Counter()\n    parts_tree_counter = collections.Counter()\n\n    for sent in data:\n        for line in sent:\n            word_counter.update([line[0]])  # add word\n            mistakes_counter.update([line[1]])\n            parts_speech_counter.update([line[2]])\n            parts_tree_counter.update([line[3]])\n\n    # words to ids\n    self.word_to_id = collections.OrderedDict([(self.PAD, 0)])\n    for word, count_w in word_counter.most_common():\n        if word not in self.word_to_id:\n            self.word_to_id[word] = len(self.word_to_id) + 1\n\n    self.singletons = [word for word in word_counter if word_counter[word] == 1]  # единички\n\n    # mistakes to ids\n    self.mistakes_to_id = collections.OrderedDict([(self.PAD, 0)])\n    for mistake, count_m in mistakes_counter.most_common():\n        if mistake not in self.mistakes_to_id:\n            self.mistakes_to_id[mistake] = len(self.mistakes_to_id)\n\n    # parts of speech to ids\n    self.speech_to_id = collections.OrderedDict([(self.PAD, 0)])\n    for speech, count_s in parts_speech_counter.most_common():\n        if speech not in self.speech_to_id:\n            self.speech_to_id[speech] = len(self.speech_to_id)\n\n    # parts of tree to ids\n    self.tree_to_id = collections.OrderedDict([(self.PAD, 0)])\n    for tree, count_t in parts_tree_counter.most_common():\n        if tree not in self.speech_to_id:\n            self.tree_to_id[tree] = len(self.tree_to_id)\n\n  def decode_sentences(self, sentences: list, max_sent_length = 20):\n    \"\"\"\n    :param sentences: raw data from get_sentences func\n    :param max_sent_length: maximum length of sent, default value is 20\n    :return: decoded_sents and labels\n    \"\"\"\n    decoded_sents = []\n    decoded_labels = []\n    \n\n    for sent in sentences:\n        # we do not take too long sentences \n        if len(sent) >= max_sent_length:\n            continue\n        else:\n            self.lengths.append(len(sent))\n\n        #decoded_sent[0] - words, [1] - tokens, [2] - trees\n        decoded_sent = np.zeros((3, max_sent_length))\n        decoded_label = np.zeros(max_sent_length)\n\n        decoded_sent[:] = self.mistakes_to_id[self.PAD]\n        decoded_label[:] = self.mistakes_to_id[self.PAD]\n\n        for word_line_ind, word_line in enumerate(sent):\n            decoded_sent[0][word_line_ind] = self.word_to_id[word_line[0]]\n            decoded_sent[1][word_line_ind] = self.speech_to_id[word_line[2]]\n            decoded_sent[2][word_line_ind] = self.tree_to_id[word_line[3]]\n\n            decoded_label[word_line_ind] = self.mistakes_to_id[word_line[1]]\n\n        decoded_sents.append(decoded_sent)\n        decoded_labels.append(decoded_label)\n\n    return decoded_sents, decoded_labels\n\n  # is not used in a new version \n  def get_batch(self, sentences: list, labels:list, batch_size:int):\n    \"\"\"\n    :param sentences: data in numeric form - words, mistakes (labels), part_speech, tree\n    sentences are in format:\n    [[[tokens, part_speech, tree], [labels]], [[tokens, part_speech, tree], [labels]]]\n    :param batch_size: the size of batch\n    yields: batch\n    \"\"\"\n    x, y = sentences, labels\n    n_samples = len(x)\n\n    batches = []\n\n    # Shuffle at the start of epoch\n    indices = np.arange(n_samples)\n    np.random.shuffle(indices)\n\n    for start in range(0, n_samples, batch_size):\n        end = min(start + batch_size, n_samples)\n\n        batch_idx = indices[start:end]\n        x_s = np.array(x, \"int_\")[batch_idx]\n        y_s = np.array(y, \"int_\")[batch_idx]\n\n        data_local = [(x, y) for x, y in zip(x_s, y_s)]\n        batches.append(data_local)\n    return batches\n  \n  def nextBatch(self, X, y, start_index):\n        last_index = start_index + config[\"batch_size\"]\n        X_batch = list(X[start_index:min(last_index, len(X))])\n        y_batch = list(y[start_index:min(last_index, len(X))])\n        if last_index > len(X):\n            left_size = last_index - (len(X))\n            for i in range(left_size):\n                index = np.random.randint(len(X))\n\n                X_batch.append(X[index])\n                y_batch.append(y[index])\n        X_batch = np.array(X_batch)\n        y_batch = np.array(y_batch)\n        return X_batch, y_batch\n\n  def get_train_data(self, data: list, train_size=0.8, val_size=0.05):\n    \"\"\"\n    :param data: all_data in list format with labels\n    :param batch_size: the size of batch\n    :return: yields batch\n    \"\"\"\n    X, y = self.decode_sentences(data)\n    num_samples = len(X)\n    split_point = (1 - train_size) / 2\n\n    X_train = X[:int(num_samples * train_size)]\n    y_train = y[:int(num_samples * train_size)]\n\n    X_val = X[int(num_samples * train_size):int(num_samples * (train_size + val_size))]\n    y_val = y[int(num_samples * train_size):int(num_samples * (train_size + val_size))]\n                                                \n    X_test = X[int(num_samples * (train_size + val_size)):]\n    y_test = y[int(num_samples * (train_size + val_size)):]\n\n    return X_train, y_train, X_val, y_val, X_test, y_test\n  \n  def encode_one_sent(self, sent, mode=\"tokens\"):\n    if mode == \"tree\":\n      encoder = self.tree_to_id\n    elif mode == \"mistakes\":\n      encoder = self.mistakes_to_id\n    elif mode == \"words\":\n      encoder = self.word_to_id\n    else:\n      encoder = self.speech_to_id\n\n    encoded_sent = [encoder[w] for w in sent]\n    return encoded_sent \n\n  def decode_one_sent(self, sent, mode=\"tokens\"):\n    if mode == \"tree\":\n      decoder = self.tree_to_id\n    elif mode == \"mistakes\":\n      decoder = self.mistakes_to_id\n    elif mode == \"words\":\n      decoder = self.word_to_id\n    else:\n      decoder = self.speech_to_id\n\n    decoder_ = {v[1]:v[0] for v in decoder.items()}\n\n    decoded_sent = [decoder_[w] for w in sent]\n    return decoded_sent","execution_count":6,"outputs":[]},{"metadata":{"id":"LahVidNhJxdV","trusted":true,"outputId":"d2e47759-be3f-48df-ee94-f9941b8b21ca"},"cell_type":"code","source":"manager = DataManager()\nmanager.build_vocabs(data)\n\nx_train, y_train, x_val, y_val, x_test, y_test = manager.get_train_data(data)\nassert len(x_train) == len(y_train)\nprint(f\"The size of training set is {len(x_train)}, the size of validation set is {len(x_val)}, the size of testing set is {len(x_test)}\")","execution_count":7,"outputs":[{"output_type":"stream","text":"The size of training set is 322653, the size of validation set is 20166, the size of testing set is 60498\n","name":"stdout"}]},{"metadata":{"trusted":true,"id":"LaVJWLk-2GNs"},"cell_type":"code","source":"X_train = [i[1] for i in x_train]\nX_val = [i[1] for i in x_val]\nX_test = [i[1] for i in x_test]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/working\") #here kaggle was used, so i change dir for developing","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here you can choose what to do: detection or classification**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_detection_errors(data):\n    data_copy = data \n    for sent_ind, sent in enumerate(data):\n        for w_ind in range(len(sent)):\n            if sent[w_ind] > 1:\n                data_copy[sent_ind][w_ind] = 2\n    return data_copy\n\nY_train = make_detection_errors(y_train)\nY_val = make_detection_errors(y_val)\nY_test = make_detection_errors(y_test)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"id":"1_g4P1LL2GNw"},"cell_type":"code","source":"def make_labels_sents(data):\n    all_sents = np.zeros(len(data))\n    \n    for sent_ind, sent in enumerate(data):\n        for w in sent:\n          if w > 1:\n            all_sents[sent_ind] = 1\n    return all_sents\n\nY_train = make_labels_sents(y_train)\nY_val = make_labels_sents(y_val)\nY_test = make_labels_sents(y_test)","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start working with Model"},{"metadata":{"id":"X3JS-JJa8V6y","trusted":true},"cell_type":"code","source":"config = {\n    \"epoch\": 20,\n    \"hidden_size\": 128,\n    \"lr\":  3*np.e - 5,\n    \"n_layers\": 4,\n    \"length\": 20,\n    \"batch_size\": 32,\n    \"optimizer\": \"Adam\", \n    \"vocab_size\": 31, \n    \"early_stop\": True, \n    \"binary\": True, \n    \"pad_idx\": 0, \n    \"ignore_index\": 0, \n    \"output_dim\": 3\n}\n\nconfig[\"vocab_size\"] = len(manager.speech_to_id)\n\niterations = len(X_train) // config[\"batch_size\"] #how often we can learn the network for each epoch \nval_iterations = len(X_val) // config[\"batch_size\"]","execution_count":12,"outputs":[]},{"metadata":{"id":"e6FbE9fOF_PB","trusted":true},"cell_type":"code","source":"class ModelDetectionBinary(nn.Module):\n    def __init__(self, config, manager):\n      \n        self.embedding_dim = 200\n        self.hidden_dim = config[\"hidden_size\"]\n        self.vocab_size = config[\"vocab_size\"] \n        self.num_layers = config[\"n_layers\"]\n        self.tag_to_ix = manager.mistakes_to_id\n        self.learning_rate = config[\"lr\"]\n    \n        super().__init__()\n        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim, padding_idx=config[\"pad_idx\"])\n        \n        self.lstm = nn.LSTM(self.embedding_dim, \n                            self.hidden_dim, \n                            num_layers = self.num_layers, \n                            bidirectional = True, \n                            batch_first = True)\n        \n        self.linear_1 = nn.Linear(self.hidden_dim * 2, 3)\n\n    def forward(self, text):\n        text = self.embedding(text)\n        \n        outputs, (hidden, cell) = self.lstm(text)\n        \n        l1 = self.linear_1(outputs)\n        outputs = torch.sigmoid(l1)\n        return outputs","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SimpleModel(nn.Module):\n    def __init__(self, config, manager):\n      \n        self.embedding_dim = 200\n        self.hidden_dim = config[\"hidden_size\"]\n        self.vocab_size = config[\"vocab_size\"] \n        self.num_layers = config[\"n_layers\"]\n        self.tag_to_ix = manager.mistakes_to_id\n        self.learning_rate = config[\"lr\"]\n        self.output_dim = config[\"output_dim\"]\n    \n        super().__init__()\n        \n        self.lstm = nn.LSTM(self.vocab_size, \n                            self.hidden_dim, \n                            num_layers = 2, \n                            bidirectional = True, \n                            batch_first = True) #bidirectional stacked layers\n        \n        self.linear_1 = nn.Linear(self.hidden_dim * 2, 1)\n\n    def forward(self, text):\n        #embedded = self.embedding(text)\n        #.view(len(text), 1, -1)\n        outputs, (hidden, cell) = self.lstm(text)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n        #hidden = [batch size, hid dim * num directions]\n\n        l1 = self.linear_1(hidden)\n        \n        outputs = torch.sigmoid(l1)\n        return outputs","execution_count":null,"outputs":[]},{"metadata":{"id":"cc-PsS15I_sf","trusted":true},"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\ndef init_weights(model):\n    for name, param in model.named_parameters():\n        nn.init.normal_(param.data, mean = 0, std = 0.1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_detection = ModelDetectionBinary(config, manager)\nmodel_detection.apply(init_weights)\n\noptim = torch.optim.Adam(model_detection.parameters(), lr=config[\"lr\"])\ncrit = nn.CrossEntropyLoss(ignore_index=config[\"ignore_index\"])","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_detection(model, optimizer, criterion, x_train, y_train, x_val, y_val):\n  best_f1_val, unprogressed = 0, 0\n  train_losses, train_metrics = [], []\n  val_losses, val_metrics = [], []\n  patient = 5\n    \n  for epoch in range(N_EPOCHS):\n    model.train()\n    print(f\"Current epoch is {epoch}\")\n    start_time_epoch = time.time()\n\n    # before every epoch shuffle the data \n    sh_index = np.arange(len(x_train))\n    np.random.shuffle(sh_index)\n    X_train = np.array(x_train)[sh_index]\n    y_train = np.array(y_train)[sh_index]\n\n    for iteration in range(iterations):\n      sentence, tags = manager.nextBatch(X_train, y_train, start_index=iteration*config[\"batch_size\"])\n      sentence = torch.tensor(sentence, dtype=torch.long).cuda()\n      tags = torch.tensor(tags, dtype=torch.long).view(-1).cuda()\n     \n      optimizer.zero_grad()\n      \n      predictions = model(sentence).cuda()\n\n      predictions = predictions.view(-1, predictions.shape[-1])\n      # predictions = predictions.view(-1, predictions.shape[-1])\n      # tags = tags.view(-1)\n      loss = criterion(predictions, tags) \n      \n      loss.backward()\n      optimizer.step()\n\n    train_losses.append(loss.detach())\n    f1, precision = count_metrics(predictions, tags)\n    train_metrics.append(f1)\n    print(f'Train Epoch: {epoch} Loss: {loss.data} Precision {precision}, f1 {f1}')\n    print(loss.detach())\n    print(f\"Iime consumed is {-(start_time_epoch - time.time())} \\n\")\n    \n    torch.cuda.empty_cache()\n    \n    #validation pool\n    val_time = time.time()\n    for iterat in range(val_iterations):\n        sentence_val, tags_val = manager.nextBatch(x_val, y_val, start_index=iterat*config[\"batch_size\"])\n        sentence_val = torch.tensor(sentence_val, dtype=torch.long).cuda()\n        tags_val = torch.tensor(tags_val, dtype=torch.long).view(-1).cuda()\n        \n        predictions_val = model(sentence_val).cuda()\n        predictions_val = predictions_val.view(-1, predictions_val.shape[-1])\n        \n        loss_val = criterion(predictions_val, tags_val)\n        f1, precision = count_metrics(predictions_val, tags_val)\n        val_metrics.append(float(f1)) #check f1 only \n        val_losses.append(loss_val.detach())\n    print(loss_val.detach())\n    print(f\"validation epoch {epoch} took {-(val_time- time.time())} seconds and f1 is {f1}\")\n\n  if np.array(val_metrics).mean() > best_f1_val:\n    unprogressed = 0\n    best_f1_val = np.array(val_metrics).mean()\n    best_epoch = epoch\n    print(f\"saved the new best model with f1: {best_f1_val} at epoch {epoch}\")\n  else:\n    unprogressed += 1\n\n  if config[\"early_stop\"]:\n    if unprogressed >= patient:\n        print(f\"early stopped, no progress obtained within {patient} epochs\")\n        print(f\"overall best f1 is {best_f1_val} at {best_epoch} epoch\")\n        return batch_losses\n    \n  return train_losses, val_losses, train_metrics, val_metrics","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, optimizer, criterion, x_train, y_train):\n  train_losses, train_metrics = [], []\n\n  for epoch in range(10):\n    print(f\"Current epoch is {epoch}\")\n    start_time_epoch = time.time()\n\n    # before every epoch shuffle the data \n    sh_index = np.arange(len(x_train))\n    np.random.shuffle(sh_index)\n    X_train = np.array(x_train)[sh_index]\n    y_train = np.array(y_train)[sh_index]\n\n    for iteration in range(iterations):\n      sentence, tags = manager.nextBatch(X_train, y_train, start_index=iteration*config[\"batch_size\"])\n      sentence = torch.tensor(sentence, dtype=torch.long)\n      sentence = F.one_hot(sentence, num_classes=config[\"vocab_size\"]).type(torch.float).cuda()\n      tags = torch.tensor(tags, dtype=torch.float).cuda()\n        \n     \n      optimizer.zero_grad()\n      \n      predictions = model(sentence).squeeze().cuda()\n\n      # predictions = predictions.view(-1, predictions.shape[-1])\n      # tags = tags.view(-1)\n\n      loss = criterion(predictions, tags) \n      \n      loss.backward()\n      optimizer.step()\n\n    train_losses.append(loss.detach())\n    print(f'Train Epoch: {epoch} Loss: {loss.data}')\n    print(f\"Iime consumed is {-(start_time_epoch - time.time())} \\n\")\n    print(predictions)\n  return train_losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"yMoW5ohW2GOB","outputId":"cf0df9da-d5a4-4fdb-e728-99143c958c65"},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{"trusted":true,"id":"9aECGWFv2GOD"},"cell_type":"code","source":"model_det = model_detection.to(device)\ncriterion = crit.to(device)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_metrics(y_pred, y_true):\n  res = []\n  for metric, values in metrics_kinds.items():\n    metric = metric.to(device)\n    value_metric = metric(y_pred, y_true)\n    metrics_kinds[metric].append(value_metric) \n    res.append(value_metric)\n  return res","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"config[\"target_size\"] = 3","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics_kinds = {\n          metrics.F1(num_classes = config[\"target_size\"]) : []}","execution_count":25,"outputs":[]},{"metadata":{"id":"nkdUeaFEOqlz","outputId":"0c4b0272-3ebb-4205-9340-462c84f2f045","trusted":true,"collapsed":true},"cell_type":"code","source":"N_EPOCHS = config[\"epoch\"]\ntrain_losses, val_losses, train_metrics, val_metrics = train_detection(model_det, optim, criterion, X_train, Y_train, X_val, Y_val)","execution_count":27,"outputs":[{"output_type":"stream","text":"Current epoch is 0\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-d3fd1938a10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_det\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-6d7c15ef3fb9>\u001b[0m in \u001b[0;36mtrain_detection\u001b[0;34m(model, optimizer, criterion, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-4d9a6e390254>\u001b[0m in \u001b[0;36mnextBatch\u001b[0;34m(self, X, y, start_index)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"aHA5jX8qqAz5","trusted":true},"cell_type":"code","source":"def save_model(model, path = \"model.pt\"):\n  torch.save(model.state_dict(), path)","execution_count":28,"outputs":[]},{"metadata":{"id":"OqDueTnbq7lP","trusted":true},"cell_type":"code","source":"def load_model(model_class, config, manager, path=\"model.pt\"):\n  model = model_class(config, manager)\n  model.load_state_dict(torch.load(path))\n  model.eval()\n  return model\n  print(\"success\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"3ydUZYYY2GOG"},"cell_type":"code","source":"!pip install plotly\nimport plotly.graph_objects as go","execution_count":null,"outputs":[]},{"metadata":{"id":"pzrW5zXnMeV-","trusted":true},"cell_type":"code","source":"def plot_results(result:list, mode=\"training\"):\n  x = np.array([i for i in range(len(result))])\n  y = np.array(result)\n\n  fig = go.Figure()\n  \n  fig.add_trace(go.Scatter(x=x, y=y, name=mode,\n                    line_shape='linear'))\n  fig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}